experiment:
  name: Fusion_RTDETR_Training_vis_ir 
  group: RTDETR_Investigation 
  continue_with_errors: False 
  start_from_grid: 0 
  start_from_run: 0 
  search: grid

parameters:
  seed: &seed [42]
  task: [detection]

  tracker:
    ignored_files: ["*.bin,*.safetensors"]
    val_image_log_frequency: [30]

  train:
    max_epochs: [30] # RT-DETR può beneficiare di qualche epoca in più essendo più complesso
    compile: [False]
    # RT-DETR è stabile con LR leggermente più alti del vecchio DETR, 1e-5 è un buon punto di partenza
    initial_lr: [0.00001] 
    optimizer: [AdamW]
    watch_metric: [map]
  
  loss:

  model:
    name: [fusion_rtdetr] # Assicurati che corrisponda al nome nel MODEL_REGISTRY
    params:
      id2label:
        0: [person]
      threshold: [0.01] # Abbassiamo leggermente per la validazione iniziale
      pretrained_path: ["checkpoints/rtdetr_20epochs_model.safetensors"]
      

  dataset: 
    name: [wisard] 
    root: [dataset/WiSARD]
    preprocessor:
      # FONDAMENTALE: Usare il preprocessor specifico di RT-DETR
      path: ["PekingU/rtdetr_r50vd"] 
    folders: [vis_ir]
    single_class: [true]
    # Attiviamo il Modal Dropout che ha salvato il progetto l'anno scorso!
    modal_dropout: [true]
    modal_dropout_probs: [[0.2, 0.2, 0.6]] # P(IR)=20%, P(RGB)=20%, P(Fusion)=60%

  dataloader:
    num_workers: [8] # Abbassato leggermente per stabilità
    batch_size: [4] # Teniamo 1 per evitare Out Of Memory (RT-DETR è pesante)
  
  val_evaluation: 
    metrics: 

other_grids: